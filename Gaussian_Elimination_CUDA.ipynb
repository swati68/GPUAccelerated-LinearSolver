{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gaussian Elimination CUDA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "w54LyPSntCf_",
        "outputId": "662b853a-520e-4635-9b6e-1fb0db488262",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8edbfTq7tWFz",
        "outputId": "b414417c-578b-453a-b4c9-8c68a918f2f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-f574g314\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-f574g314\n",
            "Requirement already satisfied (use --upgrade to upgrade): NVCCPlugin==0.0.2 from git+git://github.com/andreinechaev/nvcc4jupyter.git in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp36-none-any.whl size=4307 sha256=6233d256c560415a76cd62a5735071772c335d7421c7b58a3e2faf3b806eaa55\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-z9qg31sb/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL-cH_mctZF_",
        "outputId": "210fda02-d797-4703-b004-ef9b11fe2b78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The nvcc_plugin extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc_plugin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoiu4Vz3IJSW"
      },
      "source": [
        "    import random\n",
        "    #def generate(n):\n",
        "    n=10;\n",
        "    s=str(n)+\"\\n\";\n",
        "    for i in range(1,n):\n",
        "      for i in range(1,n+1):\n",
        "            s += str(random.randint(0,10))+\" \";  \n",
        "      s+=\"\\n\"; \n",
        "    file1 = open(\"/content/data.txt\",\"w\")#write mode \n",
        "    file1.write(s) \n",
        "    file1.close()   \n",
        "    #return s;\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbR1MCMbWAes",
        "outputId": "b1184c1a-3824-4097-dba5-abd5a82d57ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        }
      },
      "source": [
        "%%cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <stdio.h>\n",
        "#include <device_launch_parameters.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <sys/time.h>\n",
        "#include <unistd.h>\n",
        "\n",
        "#define THREADS_PER_BLOCK 16\n",
        "\n",
        "void save_to_file(double *AB, const int a_size) {\n",
        "    FILE *f = fopen(\"/content/out.txt\", \"w+\");\n",
        "\n",
        "    fprintf(f, \"%d\\n\", a_size);\n",
        "\n",
        "    for(int i = 0; i < a_size*(a_size + 1); i++) {\n",
        "        if((i + 1) % (a_size+1) == 0) {\n",
        "            fprintf(f, \"\\n\");\n",
        "            continue;\n",
        "        }\n",
        "        fprintf(f, \"%lf \", AB[i]);\n",
        "    }\n",
        "\n",
        "    for(int i = 0; i < a_size; i++)\n",
        "        fprintf(f, \"%lf \", AB[a_size + i*(a_size + 1)]);\n",
        "    fprintf(f, \"\\n\");\n",
        "\n",
        "    fclose(f);\n",
        "}\n",
        "\n",
        "double *malloc_matrix(const int a, const int b) {\n",
        "    return (double*)malloc(sizeof(double *)*a*b);\n",
        "}\n",
        "\n",
        "double *load_from_file(int *a_size, char *name) {\n",
        "    FILE *f = fopen(name, \"r\");\n",
        "\n",
        "    int size;\n",
        "    fscanf(f, \"%d\", &size);\n",
        "    double *matrix_ab = malloc_matrix(size, size + 1);\n",
        "\n",
        "    for(int i = 0; i < size*(size + 1); i++) {\n",
        "        if((i+1) % (size + 1) == 0)\n",
        "            continue;\n",
        "        fscanf(f, \"%lf\", &matrix_ab[i]);\n",
        "    }\n",
        "\n",
        "    for(int i = 0; i < size; i++) {\n",
        "        fscanf(f, \"%lf\", &matrix_ab[size + i*(size + 1)]);\n",
        "    }\n",
        "\n",
        "    fclose(f);\n",
        "\n",
        "    *a_size = size;\n",
        "\n",
        "    return matrix_ab;\n",
        "}\n",
        "\n",
        "\n",
        "void print_matrix(double *matrix, const int a, const int b) {\n",
        "    for(int i = 0; i < a*b; i++) {\n",
        "        printf(\"%lf\\t\", matrix[i]);\n",
        "        if((i+1) % b == 0)\n",
        "            printf(\"\\n\");\n",
        "    }\n",
        "}\n",
        "\n",
        "void print_output(double *AB, const int a_size) {\n",
        "    printf(\"%d\\n\", a_size);\n",
        "\n",
        "    for(int i = 0; i < a_size*(a_size + 1); i++) {\n",
        "        if((i + 1) % (a_size+1) == 0) {\n",
        "            printf(\"\\n\");\n",
        "            continue;\n",
        "        }\n",
        "        printf(\"%lf\\t\", AB[i]);\n",
        "    }\n",
        "\n",
        "    for(int i = 0; i < a_size; i++)\n",
        "        printf(\"%lf\\t\", AB[a_size + i*(a_size + 1)]);\n",
        "    printf(\"\\n\");\n",
        "}\n",
        "\n",
        "int load_size() {\n",
        "    int size;\n",
        "    scanf(\"%d\", &size);\n",
        "    return size;\n",
        "}\n",
        "\n",
        "void load_ab_matrix(double *a, const int size) {\n",
        "    for(int i = 0; i < size*(size + 1); i++) {\n",
        "        if((i+1) % (size + 1) == 0)\n",
        "            continue;\n",
        "        scanf(\"%lf\", &a[i]);\n",
        "    }\n",
        "\n",
        "    for(int i = 0; i < size; i++) {\n",
        "        scanf(\"%lf\", &a[size + i*(size + 1)]);\n",
        "    }\n",
        "}\n",
        "\n",
        "double  *load_input(int *size) {\n",
        "    *size = load_size();\n",
        "    double *matrix_ab = malloc_matrix(*size, *size + 1);\n",
        "    load_ab_matrix(matrix_ab, *size);\n",
        "    return matrix_ab;\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void replace_zero_gpu(double *AB, int rows, int columns, int column) {\n",
        "    if(fabs(AB[column*columns + column]) <= 1e-4) {\n",
        "        int row = column;\n",
        "        for(; row < rows; row++) {\n",
        "            if(fabs(AB[row*columns + column]) > 1e-4)\n",
        "                break;\n",
        "        }\n",
        "        int threadId = blockDim.x*blockIdx.x + threadIdx.x;\n",
        "        if(threadId + column >= columns)\n",
        "            return;\n",
        "\n",
        "        int zero = column*columns + column + threadId;\n",
        "        int chosen = row*columns + column + threadId;\n",
        "        AB[zero] += AB[chosen];\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void column_elimination_gpu(double *AB, int rows, int columns, int column) {\n",
        "    int threadId = blockDim.x*blockIdx.x + threadIdx.x;\n",
        "    if(threadId >= (rows - 1 - column)*(columns - column))\n",
        "        return;\n",
        "\n",
        "    int el_row = column + threadId/(columns - column) + 1;\n",
        "    int el_col = column + threadId%(columns - column);\n",
        "    int el = el_col + el_row*columns;\n",
        "    int upper_el = el_col + column*columns;\n",
        "\n",
        "    int main_el = column + column*columns;\n",
        "    int main2_el = column + el_row*columns;\n",
        "    double f = AB[main2_el]/AB[main_el];\n",
        "\n",
        "    AB[el] -= f*AB[upper_el];\n",
        "}\n",
        "\n",
        "__global__ void multiple_column(double *AB, int rows, int columns, int row) {\n",
        "    int threadId = threadIdx.x;\n",
        "    AB[(threadId * columns) + row] *= AB[columns*(row + 1) - 1];\n",
        "}\n",
        "\n",
        "__global__ void reverse_row_elimination(double *AB, int rows, int columns, int row) {\n",
        "    int threadId = threadIdx.x;\n",
        "    int cols = columns - 2 - row;\n",
        "\n",
        "    int start_index = row*columns + row + 1;\n",
        "\n",
        "    int j = cols%2;\n",
        "    for(int i = cols/2; i > 0; i/=2) {\n",
        "        if(threadId >= i)\n",
        "            return;\n",
        "\n",
        "        AB[start_index + threadId] += (AB[start_index + threadId + i + j]);\n",
        "        AB[start_index + threadId + i + j] = 0;\n",
        "        if(j == 1)\n",
        "            i++;\n",
        "        j = i%2;\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    int x_el = (row + 1)*columns - 1;\n",
        "    int diag_el = row*columns + row;\n",
        "\n",
        "    if(diag_el + 1 != x_el) {\n",
        "        AB[x_el] -= AB[diag_el + 1];\n",
        "        AB[diag_el + 1] = 0.0;\n",
        "    }\n",
        "\n",
        "    AB[x_el] /= AB[diag_el];\n",
        "    AB[diag_el] = 1.0;\n",
        "}\n",
        "\n",
        "__global__ void sum_row(double *AB, int rows, int columns, int row) {\n",
        "    int threadId = threadIdx.x;\n",
        "\n",
        "    int j = columns%2;\n",
        "    for(int i = columns/2; i > 0; i/=2) {\n",
        "        if(threadId >= i)\n",
        "            return;\n",
        "\n",
        "        AB[threadId] += AB[threadId + i + j];\n",
        "        __syncthreads();\n",
        "        if(j == 1)\n",
        "            i++;\n",
        "        j = i%2;\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "void start_gaussian_elimination_gpu(double *AB, int rows, int cols) {\n",
        "    double *AB_gpu;\n",
        "\n",
        "    cudaMalloc(&AB_gpu, sizeof(double)*rows*cols);\n",
        "    cudaMemcpy(AB_gpu, (void*)AB, sizeof(double)*rows*cols, cudaMemcpyHostToDevice);\n",
        "\n",
        "    int block_size;\n",
        "\n",
        "    for(int column = 0; column < cols - 1; column++) {\n",
        "        block_size = (cols - column - 1)/THREADS_PER_BLOCK + 1;\n",
        "        replace_zero_gpu<<<block_size, THREADS_PER_BLOCK>>>(AB_gpu, rows, cols, column);\n",
        "        cudaThreadSynchronize();\n",
        "\n",
        "        block_size = ((rows - column)*(cols - column) - 1)/THREADS_PER_BLOCK + 1;\n",
        "        column_elimination_gpu<<<block_size, THREADS_PER_BLOCK>>>(AB_gpu, rows, cols, column);\n",
        "        cudaThreadSynchronize();\n",
        "    }\n",
        "\n",
        "    for(int row = rows - 1; row >= 0; row--) {\n",
        "        reverse_row_elimination<<<1, cols>>>(AB_gpu, rows, cols, row);\n",
        "        multiple_column<<<1, row>>>(AB_gpu, rows, cols, row);\n",
        "\n",
        "        cudaThreadSynchronize();\n",
        "    }\n",
        "\n",
        "    cudaMemcpy(AB, (void*)AB_gpu, sizeof(double)*rows*cols, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    cudaFree(AB_gpu);\n",
        "}\n",
        "\n",
        "\n",
        "int main(int argc, char ** argv) {\n",
        "    int size;\n",
        "    double *AB = load_from_file(&size, \"/content/data.txt\");\n",
        "\n",
        "    print_output(AB, size);\n",
        "\n",
        "       \n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    cudaEventRecord(start);\n",
        "    \n",
        "    \n",
        "    start_gaussian_elimination_gpu(AB, size, size + 1);\n",
        "\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    float milliseconds = 0;\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "    \n",
        "     \n",
        "    printf(\"\\n\\n\");\n",
        "\n",
        "    print_output(AB, size);\n",
        "\n",
        "    save_to_file(AB, size);\n",
        "\n",
        "    printf(\"\\nTime Taken:  %f sec\",(milliseconds/1000));\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "9.000000\t7.000000\t4.000000\t3.000000\t2.000000\t7.000000\t0.000000\t3.000000\t4.000000\t4.000000\t\n",
            "1.000000\t10.000000\t3.000000\t10.000000\t0.000000\t6.000000\t9.000000\t0.000000\t6.000000\t5.000000\t\n",
            "2.000000\t1.000000\t0.000000\t10.000000\t5.000000\t9.000000\t2.000000\t0.000000\t6.000000\t9.000000\t\n",
            "4.000000\t4.000000\t10.000000\t7.000000\t9.000000\t10.000000\t0.000000\t10.000000\t3.000000\t4.000000\t\n",
            "6.000000\t10.000000\t6.000000\t1.000000\t0.000000\t7.000000\t10.000000\t9.000000\t7.000000\t7.000000\t\n",
            "4.000000\t7.000000\t0.000000\t8.000000\t5.000000\t2.000000\t9.000000\t6.000000\t1.000000\t7.000000\t\n",
            "7.000000\t10.000000\t10.000000\t9.000000\t1.000000\t4.000000\t7.000000\t10.000000\t6.000000\t8.000000\t\n",
            "1.000000\t4.000000\t2.000000\t3.000000\t0.000000\t2.000000\t6.000000\t2.000000\t6.000000\t9.000000\t\n",
            "3.000000\t1.000000\t6.000000\t3.000000\t10.000000\t1.000000\t3.000000\t1.000000\t10.000000\t3.000000\t\n",
            "0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t\n",
            "0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t\n",
            "\n",
            "\n",
            "10\n",
            "1.000000\t0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t\n",
            "0.000000\t1.000000\t0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t\n",
            "0.000000\t-0.000000\t1.000000\t0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t\n",
            "0.000000\t-0.000000\t-0.000000\t1.000000\t0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t\n",
            "0.000000\t0.000000\t0.000000\t0.000000\t1.000000\t0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t\n",
            "0.000000\t-0.000000\t-0.000000\t0.000000\t-0.000000\t1.000000\t0.000000\t0.000000\t0.000000\t0.000000\t\n",
            "-0.000000\t-0.000000\t-0.000000\t-0.000000\t0.000000\t-0.000000\t1.000000\t0.000000\t0.000000\t0.000000\t\n",
            "0.000000\t0.000000\t-0.000000\t0.000000\t-0.000000\t0.000000\t-0.000000\t1.000000\t0.000000\t0.000000\t\n",
            "0.000000\t-0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t-0.000000\t0.000000\t1.000000\t0.000000\t\n",
            "0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t1.000000\t\n",
            "-nan\t-nan\t-nan\t-nan\t-nan\t-nan\t-nan\t-nan\t-nan\t-nan\t\n",
            "\n",
            "Time Taken:  0.000666 sec\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}